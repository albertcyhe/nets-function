{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b91d12",
   "metadata": {},
   "source": [
    "\n",
    "# Metabolomics Preprocessing and Redox Ratios\n",
    "\n",
    "Unpack Metabolomics Workbench study archives, harmonise metabolite identifiers, and compute redox ratio features (GSH/GSSG, NADPH/NADP+, MetSO/Met, lactate/pyruvate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Master Configuration ===\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/NetsAnalysisProject\"\n",
    "RAW_METAB_DIR = f\"{PROJECT_DIR}/data/raw/metabolomics\"\n",
    "EXTRACT_ROOT = f\"{PROJECT_DIR}/data/processed/metabolomics/raw_tables\"\n",
    "OUTPUT_DIR = f\"{PROJECT_DIR}/data/processed/metabolomics\"\n",
    "REDOX_TABLE = f\"{OUTPUT_DIR}/redox_ratios.tsv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0764d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mount Drive & ensure directories\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive')\n",
    "except ModuleNotFoundError:\n",
    "    print('[info] Running outside Colab; ensure PROJECT_DIR is accessible.')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for path in [Path(PROJECT_DIR), Path(RAW_METAB_DIR), Path(EXTRACT_ROOT), Path(OUTPUT_DIR)]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[setup] Raw metabolomics archives under: {RAW_METAB_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a208fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install Python dependencies\n",
    "!pip install --quiet pandas openpyxl pyarrow requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba517731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper utilities for extraction and harmonisation\n",
    "import zipfile\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "STUDY_SYNONYMS = {\n",
    "    'GSH': {'gsh', 'reduced glutathione', 'glutathione (reduced)', 'hmdb0000125'},\n",
    "    'GSSG': {'gssg', 'oxidized glutathione', 'glutathione disulfide', 'hmdb0003336'},\n",
    "    'NADPH': {'nadph', 'beta-nicotinamide adenine dinucleotide phosphate reduced', 'hmdb0000221'},\n",
    "    'NADP': {'nadp', 'nadp+', 'hmdb0000219'},\n",
    "    'MetSO': {'methionine sulfoxide', 'l-methionine sulfoxide', 'hmdb0003337'},\n",
    "    'Met': {'methionine', 'l-methionine', 'hmdb0000696'},\n",
    "    'Lactate': {'lactate', 'l-lactic acid', 'hmdb0000190'},\n",
    "    'Pyruvate': {'pyruvate', 'pyruvic acid', 'hmdb0000243'},\n",
    "}\n",
    "\n",
    "RATIOS = {\n",
    "    'GSH_GSSG': ('GSH', 'GSSG'),\n",
    "    'NADPH_NADP': ('NADPH', 'NADP'),\n",
    "    'MetSO_Met': ('MetSO', 'Met'),\n",
    "    'Lactate_Pyruvate': ('Lactate', 'Pyruvate'),\n",
    "}\n",
    "\n",
    "\n",
    "def safe_extract(archive: Path, dest: Path):\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "    if archive.suffix.lower() == '.zip':\n",
    "        with zipfile.ZipFile(archive, 'r') as zf:\n",
    "            zf.extractall(dest)\n",
    "    elif archive.suffix.lower() in {'.tar', '.gz', '.bz2', '.tgz', '.tar.gz'}:\n",
    "        with tarfile.open(archive, 'r:*') as tf:\n",
    "            tf.extractall(dest)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported archive format: {archive}')\n",
    "\n",
    "\n",
    "def find_tables(root: Path) -> List[Path]:\n",
    "    patterns = ['*.csv', '*.tsv', '*.txt', '*.xlsx']\n",
    "    files = []\n",
    "    for pattern in patterns:\n",
    "        files.extend(root.rglob(pattern))\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_table(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        if path.suffix.lower() == '.csv':\n",
    "            return pd.read_csv(path)\n",
    "        if path.suffix.lower() == '.tsv' or path.suffix.lower() == '.txt':\n",
    "            return pd.read_csv(path, sep='\t')\n",
    "        if path.suffix.lower() == '.xlsx':\n",
    "            return pd.read_excel(path)\n",
    "    except Exception as exc:\n",
    "        print(f\"[warn] Failed to load {path}: {exc}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "def normalise_column_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def detect_hmdb_column(df: pd.DataFrame) -> str | None:\n",
    "    for col in df.columns:\n",
    "        if 'hmdb' in col.lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def detect_metabolite_column(df: pd.DataFrame) -> str | None:\n",
    "    for col in df.columns:\n",
    "        lower = col.lower()\n",
    "        if 'metabolite' in lower or 'compound' in lower or 'analyte' in lower or 'name' == lower:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def melt_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = normalise_column_names(df)\n",
    "    hmdb_col = detect_hmdb_column(df)\n",
    "    name_col = detect_metabolite_column(df)\n",
    "    id_col = hmdb_col if hmdb_col else name_col\n",
    "    if id_col is None:\n",
    "        raise ValueError('No HMDB or metabolite name column detected')\n",
    "    meta_cols = [id_col]\n",
    "    data_cols = [c for c in df.columns if c not in meta_cols]\n",
    "    tidy = df.melt(id_vars=id_col, value_vars=data_cols, var_name='sample', value_name='intensity')\n",
    "    tidy = tidy.dropna(subset=['intensity'])\n",
    "    tidy['feature_id'] = tidy[id_col].astype(str).str.strip()\n",
    "    tidy['sample'] = tidy['sample'].astype(str).str.strip()\n",
    "    return tidy[['feature_id', 'sample', 'intensity']]\n",
    "\n",
    "\n",
    "def match_feature(feature: str, target: str) -> bool:\n",
    "    feature_clean = feature.lower()\n",
    "    synonyms = STUDY_SYNONYMS[target]\n",
    "    return feature_clean in synonyms\n",
    "\n",
    "\n",
    "def harmonise_feature_id(feature: str) -> str:\n",
    "    feat_lower = feature.lower()\n",
    "    for label, synonyms in STUDY_SYNONYMS.items():\n",
    "        if feat_lower in synonyms:\n",
    "            return label\n",
    "    return feature\n",
    "\n",
    "\n",
    "def calculate_ratios(tidy: pd.DataFrame) -> pd.DataFrame:\n",
    "    tidy = tidy.copy()\n",
    "    tidy['harmonised_id'] = tidy['feature_id'].apply(harmonise_feature_id)\n",
    "    ratios = []\n",
    "    for ratio_name, (num_label, den_label) in RATIOS.items():\n",
    "        numerator = tidy[tidy['harmonised_id'].str.lower() == num_label.lower()]\n",
    "        denominator = tidy[tidy['harmonised_id'].str.lower() == den_label.lower()]\n",
    "        if numerator.empty or denominator.empty:\n",
    "            continue\n",
    "        merged = numerator.merge(denominator, on='sample', suffixes=('_num', '_den'))\n",
    "        merged['value'] = merged['intensity_num'] / merged['intensity_den']\n",
    "        merged = merged[['sample', 'value']]\n",
    "        merged['metric'] = ratio_name\n",
    "        ratios.append(merged)\n",
    "    if not ratios:\n",
    "        return pd.DataFrame()\n",
    "    combined = pd.concat(ratios, ignore_index=True)\n",
    "    pivot = combined.pivot(index='sample', columns='metric', values='value')\n",
    "    pivot.index.name = 'sample_id'\n",
    "    return pivot\n",
    "\n",
    "\n",
    "def process_archive(archive: Path) -> pd.DataFrame:\n",
    "    dataset_name = archive.stem\n",
    "    extract_dir = Path(EXTRACT_ROOT) / dataset_name\n",
    "    safe_extract(archive, extract_dir)\n",
    "    tables = find_tables(extract_dir)\n",
    "    ratio_frames = []\n",
    "    for table_path in tables:\n",
    "        df = load_table(table_path)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        try:\n",
    "            tidy = melt_table(df)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        ratio_df = calculate_ratios(tidy)\n",
    "        if not ratio_df.empty:\n",
    "            ratio_df['dataset'] = dataset_name\n",
    "            ratio_frames.append(ratio_df)\n",
    "    if not ratio_frames:\n",
    "        print(f\"[warn] No ratios generated for {archive}\")\n",
    "        return pd.DataFrame()\n",
    "    merged = pd.concat(ratio_frames)\n",
    "    merged = merged.groupby(level=0).mean()\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bb7c89",
   "metadata": {},
   "source": [
    "### Process all metabolomics archives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afe1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "archives = sorted(Path(RAW_METAB_DIR).glob('*.zip'))\n",
    "all_ratios = []\n",
    "\n",
    "for archive in archives:\n",
    "    print(f\"==== Processing {archive.name} ====\")\n",
    "    ratios = process_archive(archive)\n",
    "    if not ratios.empty:\n",
    "        all_ratios.append(ratios)\n",
    "\n",
    "if not all_ratios:\n",
    "    raise RuntimeError('No ratio tables were generated. Check archive contents and column naming.')\n",
    "\n",
    "combined = pd.concat(all_ratios, axis=0)\n",
    "combined = combined.loc[:, sorted([c for c in combined.columns if c in RATIOS.keys()])]\n",
    "combined.to_csv(REDOX_TABLE, sep='\t')\n",
    "combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'Redox ratio table written to: {REDOX_TABLE}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
